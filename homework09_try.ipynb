{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgz7upsyUYpllViWzoxVKl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/n-bzy/iannwtf/blob/main/homework09_try.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BL0gPTef0bbL",
        "outputId": "3e14b7dd-be7e-4c9d-ee1d-e338c99ebf00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[b'aircraft carrier', b'airplane', b'alarm clock', b'ambulance', b'angel', b'animal migration', b'ant', b'anvil', b'apple', b'arm']\n",
            "141545 images to train on\n"
          ]
        }
      ],
      "source": [
        "from codecs import xmlcharrefreplace_errors\n",
        "import os\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "import urllib\n",
        "categories = [line.rstrip(b'\\n') for line in urllib.request.urlopen('https://raw.githubusercontent.com/googlecreativelab/quickdraw-dataset/master/categories.txt')]\n",
        "print(categories[:10])\n",
        "category = 'candle'\n",
        "\n",
        "# Creates a folder to download the original drawings into.\n",
        "# We chose to use the numpy format : 1x784 pixel vectors, with values going from 0 (white) to 255 (black). We reshape them later to 28x28 grids and normalize the pixel intensity to [-1, 1]\n",
        "\n",
        "if not os.path.isdir('npy_files'):\n",
        "    os.mkdir('npy_files')\n",
        "    \n",
        "url = f'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/{category}.npy'  \n",
        "urllib.request.urlretrieve(url, f'npy_files/{category}.npy')\n",
        "\n",
        "images = np.load(f'npy_files/{category}.npy')\n",
        "print(f'{len(images)} images to train on')\n",
        "\n",
        "# You can limit the amount of images you use for training by setting :\n",
        "train_images = images[:10000]\n",
        "# You should also define a samller subset of the images for testing..\n",
        "test_images = images[10000:12500]\n",
        "# TODO\n",
        "\n",
        "# Notice that this to numpy format contains 1x784 pixel vectors, with values going from 0 (white) to 255 (black). We reshape them later to 28x28 grids and normalize the pixel intensity to [-1, 1]\n",
        "def preprocess(images, batch_size):\n",
        "    images = tf.data.Dataset.from_tensor_slices(images)\n",
        "    images = images.map(lambda img: tf.reshape(img, shape=(28,28,1)))\n",
        "    images = images.map(lambda img: tf.cast(img, tf.float32))\n",
        "    images = images.map(lambda img: (img/128 - 1.))\n",
        "    images = images.shuffle(1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return images\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_images = preprocess(train_images, batch_size)\n",
        "test_images = preprocess(test_images, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# Display one exampe image of a candle\n",
        "for x in train_images.take(1):\n",
        "    img = tf.cast(tf.floor(x*128+1), tf.uint32)[-1,:,:,-1]\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "p7TtQvUdoDWf",
        "outputId": "c5fa3585-47e2-47b3-dc60-dc3623ac32d8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAADR0lEQVR4nO3dwUrDUBBA0UT8/1+OKxdCyas16bsx5ywVwc1loMO8rtu2LUDPx+x/AHhMnBAlTogSJ0SJE6I+B7/3US6cb330Q5MTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlToga3XNygnV9eL73FK8l3ofJCVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IcjJ2MaNzMydl/4fJCVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEueecYO/m0r0m30xOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUk7EJRmdhZ/3tXzlXey+TE6LECVHihChxQpQ4IUqcECVOiLLnfMHMXSP3YXJClDghSpwQJU6IEidEiROixAlR9pwTlO8i7XA7TE6IEidEiROixAlR4oQocUKUOCHKnpOnjXag5f3tFZmcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChPY/LD3vOWvh7wvUxOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpSnMV+w93zksnhCkmOYnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClHvOCfbuPUe3otyHyQlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiHIyxmFGX33oHO53TE6IEidEiROixAlR4oQocUKUOCHKnvMEo33eaB8Iy2JyQpY4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHerZ3gqt9T6T3e9zI5IUqcECVOiBInRIkTosQJUVYpHOaqK6IqkxOixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBrdc3rrECYxOSFKnBAlTogSJ0SJE6LECVFfkYQy6c8sD88AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The Generator\n",
        "class gen(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(gen,self).__init__()\n",
        "\n",
        "        self.dense1 = tf.keras.layers.Dense(98, input_shape=(98,))\n",
        "        self.reshape = tf.keras.layers.Reshape((7,7,2))\n",
        "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
        "        self.conv1 = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=3, strides=2, padding='same', activation='relu')\n",
        "        #size is now 14x14x128\n",
        "        self.conv2 = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same', activation='relu')\n",
        "        #size is now 28x28x64\n",
        "        self.layer_out = tf.keras.layers.Conv2D(filters=1, kernel_size=3, padding='same', activation='tanh')\n",
        "        #size is now 28x28x1\n",
        "\n",
        "    @tf.function\n",
        "    def __call__(self,x):\n",
        "        x = self.dense1(x)\n",
        "        x = self.reshape(x)\n",
        "        x = self.batchnorm(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.layer_out(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "#The Discriminator\n",
        "class disc(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(disc,self).__init__()\n",
        "\n",
        "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
        "        #achtung, wenn nicht model.fit benutzt wird muss hier zwischen training true und false unterschieden werden weil dropout nur während des trainings aktiv ist \n",
        "        self.dropout = tf.keras.layers.Dropout(0.2)\n",
        "\n",
        "        self.layer1 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu')\n",
        "        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=2, strides=2)\n",
        "        # Image size 14x14\n",
        "        self.layer2 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu')\n",
        "        self.pool2 = tf.keras.layers.MaxPool2D(pool_size=2, strides=2)\n",
        "        # Image size 7x7\n",
        "        self.layer3 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu')\n",
        "        self.pool3 = tf.keras.layers.GlobalAveragePooling2D()\n",
        "        #Vector size 1x7\n",
        "        self.layer_out = tf.keras.layers.Dense(1,activation = \"sigmoid\")\n",
        "\n",
        "    @tf.function\n",
        "    def __call__(self, x, train=True):\n",
        "        x = self.batchnorm(x)\n",
        "        x = self.dropout(x, training = train)\n",
        "        x = self.layer1(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.pool3(x)\n",
        "        x = self.layer_out(x)\n",
        "        return x\n",
        "\n",
        "#The complete network\n",
        "class gan(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(gan,self).__init__()\n",
        "\n",
        "        self.gen = gen()\n",
        "        self.disc = disc()\n",
        "        #specify metrics, optimizer, loss function\n",
        "        self.metrics_list = [tf.keras.metrics.Mean(name=\"loss\")]\n",
        "        self.optimizer = tf.keras.optimizers.Adam()\n",
        "        self.loss = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "    #Noise for Generator\n",
        "    \"\"\"\n",
        "    def get_noise():\n",
        "        noise = tf.random.normal([batch_size, 1, 98])\n",
        "        return noise\n",
        "    \"\"\"\n",
        "\n",
        "    @tf.function\n",
        "    def __call__(self,real,training=False):\n",
        "        #noise = self.get_noise()\n",
        "        noise = tf.random.normal([batch_size, 1, 98])\n",
        "        fake = self.gen(noise)\n",
        "\n",
        "        decide_fake = self.disc(fake, training)\n",
        "        decide_real = self.disc(real, training)\n",
        "\n",
        "        return decide_fake, decide_real\n",
        "\n",
        "    @tf.function\n",
        "    def train(self,data):\n",
        "        real = data\n",
        "        with tf.GradientTape() as disc_tape, tf.GradientTape() as gen_tape:\n",
        "            decision_fake, decision_real = self(real, training=True)\n",
        "            #Loss Discriminator\n",
        "            loss_fake = self.loss(decision_fake, tf.zeros_like(decision_fake))\n",
        "            loss_real = self.loss(decision_real, tf.ones_like(decision_real))\n",
        "            total_loss_disc = loss_fake + loss_real\n",
        "            #Loss Generator (it's the negative loss for discriminator's loss regarding the fake images)\n",
        "            loss_gen = - loss_fake\n",
        "\n",
        "        #Adjust weights of Discriminator \n",
        "        gradients_disc = disc_tape.gradient(total_loss_disc, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients_disc, self.trainable_variables))\n",
        "        self.metrics[0].update_state(total_loss_disc)\n",
        "\n",
        "        #Adjust weights of Generator \n",
        "        gradients_gen = gen_tape.gradient(loss_gen, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients_gen, self.trainable_variables))\n",
        "        self.metrics[0].update_state(loss_gen)\n",
        "\n",
        "        return {m.name : m.result() for m in self.metrics}\n",
        "\n",
        "    @tf.function\n",
        "    def test(self,data):\n",
        "        real = data\n",
        "        decision_fake, decision_real = self(real, training=False)\n",
        "        #Loss Discriminator\n",
        "        loss_fake = self.loss(decision_fake, tf.zeros_like(decision_fake))\n",
        "        loss_real = self.loss(decision_real, tf.ones_like(decision_real))\n",
        "        total_loss_disc = loss_fake + loss_real\n",
        "        #Loss Generator (its negative loss for discriminator's loss regarding the fake images)\n",
        "        loss_gen = - loss_fake\n",
        "\n",
        "        self.metrics[0].update_state(total_loss_disc)\n",
        "        self.metrics[0].update_state(loss_gen)\n",
        "\n",
        "        return {m.name : m.result() for m in self.metrics} \n",
        "\n",
        "def training_loop(model, train_images, test_images, epochs, generator):\n",
        "    \"\"\"Train and test the RNN for given epochs on given data\"\"\"\n",
        "\n",
        "    # Save loss and accuracy as dictionaries in a list for visualization\n",
        "    lists = []\n",
        "    #Safe generated images\n",
        "    img = []\n",
        "\n",
        "    for n in range(epochs):\n",
        "        print(f\"Epoch {n}:\")\n",
        "\n",
        "        for data in tqdm.tqdm(train_images, position=0, leave=True):\n",
        "            metrics = model.train(data)\n",
        "\n",
        "        # Add metrics to list\n",
        "        lists.append(metrics)\n",
        "        print([f\"{key}: {value.numpy()}\" for (key,value) in metrics.items()])\n",
        "        model.reset_metrics()\n",
        "\n",
        "        for data in tqdm.tqdm(test_images, position=0, leave=True):\n",
        "            metrics = model.test(data)\n",
        "\n",
        "        # Add metrics to list\n",
        "        lists.append(metrics)\n",
        "        print([f\"{key}: {value.numpy()}\" for (key,value) in metrics.items()])\n",
        "        model.reset_metrics()\n",
        "        \n",
        "        #Create Image with generator and safe it\n",
        "        new_noise = tf.random.normal([batch_size, 1, 98])\n",
        "        img.append(generator(new_noise))\n",
        "\n",
        "    return lists\n",
        "\n",
        "#initialize model\n",
        "model = gan()\n",
        "generator = gen()\n",
        "#train network\n",
        "li = training_loop(model, train_images, test_images, 5, generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLUbyB6ZoEEN",
        "outputId": "c3cd030d-5c5b-464c-d777-9f03d51fa4f1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:08<00:00, 37.16it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['loss: 0.021883388981223106']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:00<00:00, 101.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['loss: 0.0001178813909064047']\n",
            "Epoch 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:02<00:00, 114.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['loss: 1.1075419479311677e-06']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:00<00:00, 271.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['loss: 0.00011116341920569539']\n",
            "Epoch 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:02<00:00, 114.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['loss: 1.0024244829764939e-06']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:00<00:00, 277.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['loss: 0.00010611738980514929']\n",
            "Epoch 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:02<00:00, 115.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['loss: 9.658618864705204e-07']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:00<00:00, 261.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['loss: 0.00010072128497995436']\n",
            "Epoch 4:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:02<00:00, 112.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['loss: 9.612915619072737e-07']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:00<00:00, 272.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['loss: 9.468537609791383e-05']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Geklaut\n",
        "# Display the images created by the Generator while training\n",
        "k = 1\n",
        "plt.figure(figsize=(25,10))\n",
        "\n",
        "for x in img:\n",
        "    # Reduce dimensionality of images for displaying to 2D (remove batch and color channel)\n",
        "    #x = np.squeeze(x, axis=0)\n",
        "    #x = np.squeeze(x, axis=-1)\n",
        "    print(x.shape)\n",
        "    plt.subplot(1, len(img), k)\n",
        "    plt.imshow(x, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    k += 1\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "XlV2i3sovOoz",
        "outputId": "562d394a-f24a-4103-d9cd-f674b8c7a3ed"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28,)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-73a5978fca45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2643\u001b[0m         \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deprecated_parameter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2644\u001b[0m         resample=None, url=None, *, data=None, **kwargs):\n\u001b[0;32m-> 2645\u001b[0;31m     __ret = gca().imshow(\n\u001b[0m\u001b[1;32m   2646\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maspect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5624\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5626\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5627\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    696\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    697\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 698\u001b[0;31m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0m\u001b[1;32m    699\u001b[0m                             .format(self._A.shape))\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (28,) for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x720 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFIAAABNCAYAAAA1rDPVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAADkElEQVR4nO2cQYhVZRiGnzctF7NIqFlECQaJgwsXeomWQQTqQhe10E0pymwS1+6Edq2CIIrBRG2RiqsJgghatEnxDkRkIgxCNBI0mbgJjIG3xT1j422c85Pfveec8Xvgwpz7f5zz8XDuHP7znvPLNsnj81TTDawXUmQQKTKIFBlEigwiRQZRK1LSGUm/S/rpEeOS9JGkeUk/StoV32b7KTkjzwJ71hjfC2yrPtPAJ4/fVveoFWn7O+DPNUoOAOc94AqwWdILUQ12hYj/kS8Cv67YXqi+e6LYOM6DSZpm8PNnYmJi99TU1DgP/7+Ym5v7w/ZkXV2EyNvAlhXbL1Xf/QfbM8AMQK/Xc7/fDzj8aJH0S0ldxE97Fninunq/Btyz/VvAfjtF7Rkp6QvgdeB5SQvAKeBpANufAl8B+4B54C/gyKiabTO1Im0fqhk38F5YRx0lZzZBpMggUmQQKTKIFBlEigwiRQaRIoNIkUGkyCBSZBApMogikZL2SLpZBVwnVxk/LGlR0g/V51h8q+2m5DbaBuBj4E0GMcI1SbO2fx4qvWj7+Ah67AQlZ+SrwLztW7b/Bi4wCLySFZSILA233qpy7cuStqwyvq6Juth8CWy1vRP4Bji3WpGkaUl9Sf3FxcWgQ7eDEpG14ZbtO7bvV5ungd2r7cj2jO2e7d7kZG0w1ylKRF4Dtkl6WdIzwEEGgdcDhh4I2A/ciGuxG5RkNkuSjgNfAxuAM7avS3of6NueBU5I2g8sMXgq4/AIe24lauoZ8g7l2nO2e3V1ObMJIkUGkSKDSJFBpMggUmQQKTKIFBlEigwiRQaRIoNIkUFEhV+bJF2sxq9K2hrdaNspeYVuOfzaC+wADknaMVR2FLhr+xXgQ+CD6EbbTlT4dYB/44XLwBuSFNdm+4kKvx7U2F4C7gHPRTTYFRp78wu4/6g3blvG9pKiEpElb3Yt1yxI2gg8C9wZ3tHKN78k9UvuPDeNpKLb+CHhV7X9bvX328C3fsLWwYkKvz4DPpc0zyD8OjjKpttIY+GXpOnqp95qSvtsTOR6I6eIQTQism7K2QbqFkUZZuwiC6ecbeAsay+K8hBNnJGdeN6yYFGUh2hC5LpcTCQvNkE0IbJ4MZEu0YTIkiln5xi7yOo22/KU8wZwyfb1cfdRR7UoyvfAdkkLko6uWZ8zmxjyYhNEigwiRQaRIoNIkUGkyCBSZBApMoh/AA8wJ9KHW9XsAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}