{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOs7szyWDToH3AicKtqPR8z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/n-bzy/iannwtf/blob/main/incomplete_homework07_Silvie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INPUT to CNN**:  <br>\n",
        "4-tuple/quadruple containing 4 mnist images of size mxn: (digit1,digit2,digit3,digit4) <br><br>\n",
        "**OUTPUT of CNN & INPUT to RNN/LSTM**: <br>\n",
        "4-tuple containing 4 one-hot vectors representing the digit depicted on each of the 4 images <br><br>\n",
        "**TARGET & OUTPUT of RNN/LSTM**: <br>\n",
        "4-tuple containing 4 float/int values corresponding to the cummulative sum results"
      ],
      "metadata": {
        "id": "ga8CoDMz0iqW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "**RNN**: many-to-many model"
      ],
      "metadata": {
        "id": "QsCIJmYUGdyE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import data set"
      ],
      "metadata": {
        "id": "a2RqSpM7SQkN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ACooDp4pugq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "#load MNIST data\n",
        "train_ds, val_ds = tfds.load('mnist', split=['train', 'test'], as_supervised=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing step"
      ],
      "metadata": {
        "id": "brdOiHJqSWaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(data):\n",
        "    \"\"\"Preparing data sets for use in network\"\"\"\n",
        "\n",
        "    #change datatype to float\n",
        "    data = data.map(lambda x,t : (tf.cast(x, tf.float32), t))\n",
        "    #normalize the image pixel values\n",
        "    data = data.map(lambda x,t : ((x/128.)-1, t))\n",
        "\n",
        "    #get 4 datasets with data samples in random order\n",
        "    digit_1 = data.shuffle(2000)\n",
        "    digit_2 = data.shuffle(2000)\n",
        "    digit_3 = data.shuffle(2000)\n",
        "    digit_4 = data.shuffle(2000)\n",
        "\n",
        "    #create sequences of 4 digits each that will be fed as INPUT into the model\n",
        "    #zip digit 1-4: map (x1,t1), (x2,t2), (x3,t3), (x4,t4) to ((x1,t1),(x2,t2),(x3,t3),(x4,t4))\n",
        "    zipped_ds = tf.data.Dataset.zip((digit_1,digit_2,digit_3,digit_4))\n",
        "\n",
        "    #prepare target:create 5-tuple (x1,x2,x3,x4,t) with t = array containing the 4 original targets\n",
        "    zipped_ds = zipped_ds.map(lambda digit_1,digit_2,digit_3,digit_4: (digit_1[0], digit_2[0], digit_3[0], digit_4[0], [digit_1[1],digit_2[1],digit_3[1],digit_4[1]]))\n",
        "\n",
        "    #adjust input to single 4-tuple: (input,target) with input = (img1,img2,img3,img4)\n",
        "    zipped_ds = zipped_ds.map(lambda digit_1,digit_2,digit_3,digit_4, t: ((digit_1, digit_2, digit_3, digit_4), t))\n",
        "    \n",
        "    #adjust target to an array with the 4 cumulative sums\n",
        "    #create array of indices\n",
        "    indices = tf.range(4)\n",
        "    #make every 2nd series target (-> has odd index) negative\n",
        "    zipped_ds = zipped_ds.map(lambda input,t: (input, tf.where(tf.math.floormod(indices,2)==0, t, -t)))\n",
        "    #compute the cumulative sums\n",
        "    zipped_ds = zipped_ds.map(lambda input,t: (input, tf.math.cumsum(t)))\n",
        "\n",
        "    #shuffle(?neccessary), batch, prefetch data\n",
        "    preprocessed_ds = zipped_ds.shuffle(1000).batch(256).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return preprocessed_ds\n",
        "\n",
        "#-------------------------------------------------------\n",
        "# Test preprocessing and check for value and target shapes \n",
        "# (important for initializing of model with input values)\n",
        "train_test = preprocessing(train_ds)\n",
        "for input,t in train_test.take(1):\n",
        "    print(\"Input: \" + str(tf.shape(input)) + \" -> [#seriesInputElements, batchSize, xImgDimension, yImgDimension, usingGrayValues/noColorChannels]\")\n",
        "    print(\"Target: \" + str(tf.shape(t)) + \" -> [batchSize, #seriesOutputElements]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lFsPLHvypBi",
        "outputId": "e253d78f-de50-459c-81b7-dbdbd4d850cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: tf.Tensor([  4 256  28  28   1], shape=(5,), dtype=int32) -> [#seriesInputElements, batchSize, xImgDimension, yImgDimension, usingGrayValues/noColorChannels]\n",
            "Target: tf.Tensor([256   4], shape=(2,), dtype=int32) -> [batchSize, #seriesOutputElements]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN model"
      ],
      "metadata": {
        "id": "x_82L8wvS5Ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(tf.keras.Model):\n",
        "  \"\"\"Basic CNN structure\"\"\"\n",
        "  def __init__(self):\n",
        "    \"\"\"Initialize CNN blocks, pooling, optimizer, loss function\"\"\"\n",
        "    super(CNN, self).__init__()\n",
        "\n",
        "    #CNN block 1\n",
        "    self.convlayer1 = tf.keras.layers.Conv2D(filters=24, kernel_size=3, padding='same', activation='relu', input_shape=input_shape[2:])\n",
        "    self.convlayer2 = tf.keras.layers.Conv2D(filters=24, kernel_size=3, padding='same', activation='relu')\n",
        "    #pooling layer: reduce img size to 16x16\n",
        "    self.pool1 = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2))\n",
        "\n",
        "    #CNN block 2\n",
        "    self.convlayer3 = tf.keras.layers.Conv2D(filters=48, kernel_size=3, padding='same', activation='relu')\n",
        "    self.convlayer4 = tf.keras.layers.Conv2D(filters=48, kernel_size=3, padding='same', activation='relu')\n",
        "    #global pooling layer: reduce img size to 1x1 for dense layer\n",
        "    self.global_pool = tf.keras.layers.TimeDistributed(tf.keras.layers.GlobalAvgPool2D())\n",
        "\n",
        "    #output layer\n",
        "    self.out = tf.keras.layers.Dense(10, activation='softmax') #we want a one-hot vector as output\n",
        "\n",
        "  def call(self, x):\n",
        "    \"\"\"Forward propagation step for CNN\"\"\"\n",
        "    x = self.convlayer1(x)\n",
        "    x = self.convlayer2(x)\n",
        "    x = self.pool1(x)\n",
        "    x = self.convlayer3(x)\n",
        "    x = self.convlayer4(x)\n",
        "    x = self.global_pool(x)\n",
        "    y = self.out(x)\n",
        "    return y\n"
      ],
      "metadata": {
        "id": "jRbsyLCPTIaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM model"
      ],
      "metadata": {
        "id": "zduuMffmTuAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMCell(tf.keras.layers.AbstractRNNCell):\n",
        "  \"\"\"Create a LSTM cell\"\"\"\n",
        "  def __init__(self, hidden_state, cell_state):\n",
        "    super().__init__()\n",
        "\n",
        "    self."
      ],
      "metadata": {
        "id": "qaX9uDPxTw26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN model"
      ],
      "metadata": {
        "id": "r-X_Wf9ATxee"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KISvvBssTzTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training step"
      ],
      "metadata": {
        "id": "atrpLeKuTznZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create CNN model\n",
        "cnn_model = CNN()\n",
        "#create RNN model\n",
        "rnn_model = RNN()"
      ],
      "metadata": {
        "id": "E4rBlmI1T6YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "JyYjwbMdT72p"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cZAQtfZOT9pE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}