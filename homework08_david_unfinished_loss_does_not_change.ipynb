{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOihyWA4wF/n6i7rVC3GgA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/n-bzy/iannwtf/blob/main/homework08_david_unfinished_loss_does_not_change.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18NoSkPvv6Jz",
        "outputId": "cff35bba-e42a-4759-a033-d34e57f1098e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 28, 28, 1, 1) (256, 28, 28, 1, 1)\n",
            "Epoch 1/10\n",
            "235/235 [==============================] - 31s 125ms/step - loss: 0.9282 - val_loss: 0.9243\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 28s 120ms/step - loss: 0.9239 - val_loss: 0.9243\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 29s 122ms/step - loss: 0.9239 - val_loss: 0.9243\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 29s 120ms/step - loss: 0.9239 - val_loss: 0.9243\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 29s 121ms/step - loss: 0.9239 - val_loss: 0.9243\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 28s 119ms/step - loss: 0.9239 - val_loss: 0.9243\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 28s 120ms/step - loss: 0.9239 - val_loss: 0.9243\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 29s 122ms/step - loss: 0.9239 - val_loss: 0.9243\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 29s 120ms/step - loss: 0.9239 - val_loss: 0.9243\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 28s 120ms/step - loss: 0.9239 - val_loss: 0.9243\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f84062dba90>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import tqdm\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras import layers, losses\n",
        "import datetime\n",
        "\n",
        "train_ds, test_ds = tfds.load('mnist', split =['train', 'test'], as_supervised = True)\n",
        "\n",
        "def preprocessing(mnist, batch_size):\n",
        "\n",
        "    #get rid of the targets\n",
        "    mnist = mnist.map(lambda img, target: (img))\n",
        "\n",
        "    #change datatype from unit-8 to float\n",
        "    mnist = mnist.map(lambda img: (tf.cast(img, tf.float32)))\n",
        "\n",
        "    #normalize image values\n",
        "    mnist = mnist.map(lambda img: ((img/128.)-1))\n",
        "\n",
        "    #shape: (28,28,1) values in range 0 to 1\n",
        "\n",
        "    #add noise to input images, old images as targets\n",
        "        #random noise tensor\n",
        "    noise = tf.random.uniform(shape=(28,28,1), minval = 0, maxval = 1, dtype=tf.float32)\n",
        "        ##add noise tensor to input img\n",
        "    mnist = mnist.map(lambda img: ((tf.math.add(img, noise), img)))\n",
        "    mnist = mnist.map(lambda img1, img2: (tf.clip_by_value(img1, clip_value_max=0, clip_value_min=1), img2))\n",
        "        #values in input images are now 0 to 2\n",
        "        #so divide by to to have range of 0 to 1 again\n",
        "    #mnist = mnist.map(lambda noise_img, img : ((noise_img/2), img))\n",
        "\n",
        "    #could have used tf.clip.by_value(,min=,max=) instead\n",
        "\n",
        "    #add third dimension for autoencoder\n",
        "    mnist = mnist.map(lambda noise_img, img: (tf.expand_dims(noise_img, -1), tf.expand_dims(img, -1)))\n",
        "\n",
        "    #now we should have tuple (noisy_img, img) which each have the shape (28,28,1,1) and range from 0 to 1\n",
        "\n",
        "    #shuffle, batch, prefetch\n",
        "    mnist = mnist.shuffle(2000)\n",
        "    mnist = mnist.batch(batch_size)\n",
        "    mnist = mnist.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return mnist\n",
        "\n",
        "train_ds = preprocessing(train_ds, 256)\n",
        "test_ds = preprocessing(test_ds, 256)\n",
        "\n",
        "#check shape\n",
        "for noise_img, img in train_ds.take(1):\n",
        "    print(noise_img.shape, img.shape)\n",
        "\n",
        "#We have tuple (noisy_img, img) which each have the shape (batch_size, 28,28,1,1) and range from 0 to 1 in the dimension with the first 1 (i hope)\n",
        "#!! maybe i actually dont need to non-noisy img as targets\n",
        "\n",
        "#Convolutional Autoencoder to Denoise\n",
        "\n",
        "class Denoise(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(Denoise, self).__init__()\n",
        "\n",
        "        #Encoder layers:\n",
        "        self.layer1 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\",strides=2, activation=\"relu\")\n",
        "            #Image size 14x14\n",
        "        self.layer2 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding=\"same\",strides=2, activation=\"relu\")\n",
        "            #Image size 7x7\n",
        "        #Flatten Image\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "            #Vector size (batch_size, 49)\n",
        "\n",
        "        #Create Embedding of size 10 with dense layer (this is not a dense layer is it??)\n",
        "        #self.embedding = tf.keras.layers.Embedding(50, 10)\n",
        "\n",
        "        #aus silvies code\n",
        "        self.bottleneck_in = tf.keras.layers.Dense(7*7*128, activation='relu')\n",
        "        self.embedding = tf.keras.layers.Dense(10)\n",
        "        #bis hier\n",
        "\n",
        "        #Decoder layers:\n",
        "        #aus silvies code:\n",
        "        self.bottleneck_out = tf.keras.layers.Dense(7*7*128, activation='relu')\n",
        "        self.reshape = tf.keras.layers.Reshape((7,7,128))\n",
        "        #bis hier\n",
        "            #Shape now (batch_size, 7, 7, 128)\n",
        "        self.re_layer1 = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=3, padding=\"same\", strides=2, activation=\"relu\")\n",
        "            #Img size 14x14\n",
        "        self.re_layer2 = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=3, padding=\"same\", strides=2, activation=\"relu\")\n",
        "            #Img size 28x28\n",
        "        #Output layer\n",
        "        self.output_layer = tf.keras.layers.Conv2D(filters=1, kernel_size=3, padding=\"same\", activation=\"sigmoid\")\n",
        "\n",
        "    @tf.function\n",
        "    def encoder(self, input):\n",
        "        x = self.layer1(input)\n",
        "        x = self.layer2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.bottleneck_in(x)\n",
        "        x = self.embedding(x) \n",
        "\n",
        "        return x\n",
        "\n",
        "    @tf.function\n",
        "    def decoder(self, encoder_output):\n",
        "        x = self.bottleneck_out(encoder_output)\n",
        "        x = self.reshape(x)\n",
        "        x = self.re_layer1(x)\n",
        "        x = self.re_layer2(x)\n",
        "        x = self.output_layer(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    @tf.function\n",
        "    def __call__(self, input, training=False):\n",
        "        encoded = self.encoder(input)\n",
        "        decoded = self.decoder(encoded)\n",
        "\n",
        "        return decoded\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(self, data):\n",
        "        x, t = data\n",
        "        with tf.GradientTape() as tape:\n",
        "            output = self(x, training=True)\n",
        "            loss = self.compiled_loss(t, output, regularization_losses=self.losses)\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        \n",
        "        self.metrics[0].update_state(loss)\n",
        "        \n",
        "        return {m.name : m.result() for m in self.metrics}\n",
        "\n",
        "    @tf.function\n",
        "    def test_step(self, data):\n",
        "        x, t = data\n",
        "        output = self(x, training=True)\n",
        "        loss = self.compiled_loss(t, output, regularization_losses=self.losses)\n",
        "        \n",
        "        self.metrics[0].update_state(loss)\n",
        "\n",
        "        return {m.name : m.result() for m in self.metrics}\n",
        "\n",
        "autoencoder = Denoise()    \n",
        "autoencoder.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=0.5), loss=losses.MeanSquaredError())\n",
        "\n",
        "autoencoder.fit(train_ds,\n",
        "                validation_data = test_ds,\n",
        "                epochs = 10\n",
        "                )\n",
        "\n",
        "    \n",
        "\n",
        "\n"
      ]
    }
  ]
}